\Large S = -\sum_{i=1}^{N}p_i \log_2{p_i}, Энтропия Шеннона, для системы с N возможными
состояниями, где p_i – вероятности нахождения системы в -ом состоянии.

\Large IG(Q) = S_O - \sum_{i=1}^{q}\frac{N_i}{N}S_i, прирост информации (information gain, IG) при
разбиении выборки по признаку Q.
